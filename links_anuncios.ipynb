{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Este script utiliza Selenium para automatizar la navegación en Fotocasa y extraer enlaces de anuncios.\n",
    "\n",
    "FUNCIONAMIENTO:\n",
    "1. Lee un archivo CSV ('start_urls.csv') que contiene las URLs de búsqueda.\n",
    "2. Para cada URL:\n",
    "   - Inicializa un navegador Chrome en modo incógnito y, opcionalmente, en modo sin interfaz gráfica (headless).\n",
    "   - Usa agentes de usuario aleatorios y técnicas para evitar detección.\n",
    "   - Accede a la página y espera aleatoriamente para simular comportamiento humano.\n",
    "   - Verifica si la página está bloqueada y detiene el proceso si es necesario.\n",
    "   - Espera a que la página cargue completamente y cierra pop-ups si aparecen.\n",
    "   - Obtiene el número total de anuncios disponibles en la página.\n",
    "   - Si hay anuncios:\n",
    "     - Hace scroll hasta el final de la página para cargar todos los anuncios.\n",
    "     - Extrae los enlaces de cada anuncio y los almacena en una lista.\n",
    "     - Guarda los enlaces en un archivo CSV ('links_anuncios.csv'), junto con la fecha y el código postal extraído de la URL.\n",
    "3. Espera un tiempo aleatorio entre iteraciones para reducir el riesgo de bloqueo.\n",
    "4. Cierra el navegador al finalizar.\n",
    "\n",
    "USO:\n",
    "Este script es útil para realizar web scraping en Fotocasa de manera automatizada, recopilando enlaces de anuncios de viviendas sin ser detectado fácilmente.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from time import sleep\n",
    "import random\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para evitar bloqueos\n",
    "def esperar_aleatoriamente(min_seg=5, max_seg=15):\n",
    "    tiempo = random.randint(min_seg, max_seg)\n",
    "    sleep(tiempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo de csv\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df = pd.read_csv('datos/start_urls.csv', header=None)[0]\n",
    "for website in df:\n",
    "    print(website)\n",
    "    # Inicializar el driver\n",
    "    options = Options()\n",
    "    options.add_argument('--incognito')\n",
    "    options.add_argument('--headless')  # Opcional: Ejecutar sin interfaz gráfica\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option('useAutomationExtension', False)\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    service = Service('chromedriver/chromedriver.exe')\n",
    "    # Rotar agentes de usuario para evitar detección\n",
    "    user_agents = [\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "        \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    ]\n",
    "    options.add_argument(f'user-agent={random.choice(user_agents)}')\n",
    "    # Inicializar el driver\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    esperar_aleatoriamente()  # Esperar antes de interactuar\n",
    "\n",
    "    # Ingresar a la pagina\n",
    "    driver.get(str(website))\n",
    "    esperar_aleatoriamente()  # Esperar antes de interactuar\n",
    "    driver.maximize_window() # Maximizar la ventana\n",
    "    \n",
    "\n",
    "    # Verificar si la pagina esta bloqueada\n",
    "    bloqueo = driver.find_elements(By.XPATH, '//html/body/div/h1') if driver.find_elements(By.XPATH, '//html/body/div/h1') else 0\n",
    "    if bloqueo != 0:\n",
    "        print(\"Pagina bloqueada\")\n",
    "        driver.quit()\n",
    "        break\n",
    "\n",
    "    # Esperar a que cargue la pagina\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"App\"]')))\n",
    "    \n",
    "    # Espera a que el popup sea visible y cierra el popup\n",
    "    try:\n",
    "        close_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//*[@id=\"didomi-notice-agree-button\"]'))\n",
    "        )\n",
    "        close_button.click()\n",
    "    except Exception as e:\n",
    "        print(\"No se pudo cerrar el popup:\", e)\n",
    "    \n",
    "    # Obtener el numero de anuncios     \n",
    "    nauncios = driver.find_elements(By.XPATH, '//h2[@class=\"re-SearchPage-counterTitle\"]') if driver.find_elements(By.XPATH, '//h2[@class=\"re-SearchPage-counterTitle\"]') else 0\n",
    "    if nauncios == 0:\n",
    "        counter = 0\n",
    "    else:\n",
    "        for n in nauncios:\n",
    "            counter = n.text.split(\" \")[0]\n",
    "    print(counter)\n",
    "\n",
    "    # Obtener los links de los anuncios\n",
    "    links = []\n",
    "    if int(counter) == 0: # Si no hay anuncios\n",
    "        print(\"No se encontraron anuncios\")\n",
    "        esperar_aleatoriamente(1, 5)  # Esperar antes de seguir\n",
    "        driver.quit()\n",
    "        continue # Continuar con el siguiente website\n",
    "        \n",
    "    else:    \n",
    "        # Hacer scroll hasta el final de la pagina\n",
    "        height = driver.execute_script(\"return Math.max( document.body.scrollHeight, document.body.offsetHeight, document.documentElement.clientHeight, document.documentElement.scrollHeight, document.documentElement.offsetHeight );\")\n",
    "        for e in range(0, height, 700):\n",
    "            driver.execute_script('window.scrollTo(0, {});'.format(e))\n",
    "            esperar_aleatoriamente(1, 5)  # Esperar antes de seguir\n",
    "        \n",
    "        for i in range(1, int(counter)+1): # Obtener los links de los anuncios\n",
    "            try:\n",
    "                link = driver.find_element(By.XPATH, '//section[@class=\"re-SearchResult\"]/article[{}]/a'.format(i)) # Obtener el link\n",
    "                links.append(link.get_attribute('href'))\n",
    "                esperar_aleatoriamente()  # Esperar antes de seguir\n",
    "            except:\n",
    "                print(\"No se pudo obtener el link\")\n",
    "\n",
    "            print(links)\n",
    "        \n",
    "        cd_postal = website.split(\"zipCode=\")[1] # Obtener el codigo postal\n",
    "        fecha = datetime.datetime.now().strftime(\"%Y-%m-%d\") # Obtener la fecha actual\n",
    "\n",
    "        # Guardar los links en un archivo csv\n",
    "        links_df = pd.DataFrame(links, columns=['links'])\n",
    "        links_df.insert(0, 'fecha', fecha)\n",
    "        links_df.insert(1, 'codigo_postal', cd_postal)\n",
    "        links_df.to_csv('datos/links_anuncios.csv', mode='a', index=False, header=False)\n",
    "        print(\"Links guardados\")\n",
    "\n",
    "        esperar_aleatoriamente(60, 90)  # Esperar antes de seguir\n",
    "    \n",
    "    # Cerrar el driver\n",
    "    driver.quit()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "selenium_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
